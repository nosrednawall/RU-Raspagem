name: RU Scraper Automation

on:
  # Executa a cada 2 horas
  schedule:
    - cron: '0 */2 * * *'
  # Permite execução manual também
  workflow_dispatch:

jobs:
  scrape-ru:
    runs-on: ubuntu-latest
    
    steps:
    # 1. Fazer checkout do repositório
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        
    # 2. Configurar R
    - name: Setup R
      uses: r-lib/actions/setup-r@v2
      
    # 3. Instalar pacotes necessários
    - name: Install dependencies
      uses: r-lib/actions/setup-r-dependencies@v2
      with:
        packages: |
          tidyverse
          rvest
          dplyr
        needs: website
        
    # 4. Executar o script R
    - name: Run scraper
      run: Rscript ru-raspagem.R
      
    # 5. Fazer commit dos dados atualizados
    - name: Commit and push if changed
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add dados/*.csv
        git diff --quiet && git diff --staged --quiet || git commit -m "Auto-update: dados RU $(date)"
        git push
